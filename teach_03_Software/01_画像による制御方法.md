# 画像による制御方法

ここでは、Raspberry Pi Camera と、Raspberry Pi Zero を使った方法をご紹介します。

## 初めに

python ファイルの初めに宣言するインポートを以下に示します。

```
import picamera  # Raspberry Pi Camera用
import picamera.array

from matplotlib import image  # 画像編集用
import numpy as np
import cv2
```

## 手順

1. 画像を撮影する
2. コーンの色のみを抽出する
3. 抽出した画像を 2 値化する
4. 2 値化する画像の中心座標を求める

### 1. 画像を撮影する

Raspberry Pi では、カメラを接続し、以下のコードを動かすことで画像を取得することができます。（カメラの接続方法、初期設定等は調べて実行してください。）

```
camera.start_preview()
camera.capture('image.jpg')
camera.stop_preview()
```

これを python で実行すると、"image.jpg"というファイルが保存されます。

画像を撮影し、それを Open CV で読み込むということを行ってもいいですが、それだと二度手間なので、撮影した画像データを直接 Open CV で読み込む方法も紹介します。

```
with picamera.PiCamera() as camera:
        with picamera.array.PiRGBArray(camera) as stream:
            self.savesign = (self.savesign + 1) % 5
            camera.resolution = self.resolution
            camera.framerate = self.framerate
            camera.capture(stream, 'bgr', use_video_port=True)
            image = stream.array
```

このようにすると、"image"という変数に読み込んだ画像データが格納されます。実際の完成コードではこの image というデータを使い画像の色抽出を行います。

### 2. コーンの色のみを抽出する

色抽出を行うコードは 1 つのファイルにまとめ、モジュールとして使えるようにした方が便利です。ファイルの先頭には"初めに"にある import を追加してください。

PC での画像データは RGB という値が 1 ピクセル当たりに割り振られています。画像の抽出では、下限値の RGB から上限値の RGB の間に入る色のみを抽出するという作業を行います。

例）下限値=RGB(10,130,45), 上限値=RGB(120,225,120)
→RGB(10~120, 130~225, 45~120)

しかし、RGB の値で上限下限を決めても赤色のみを抽出することは難しいです。RGB はそれぞれの色を示す値のため、暗い赤から明るい赤の間という指定の仕方が難しいためです。

そこで活躍するのが HSV という表し方です。この表し方は、上限値下限値を適切に決めることができます。H=色相, S=彩度, V=明度を表しており、色を指定して再度と明度の上限と下限をとれば、暗い赤から明るい赤までの間の色を抽出することができるからです。\*HSV は H の値の範囲が 1~179 までのため注意してください。詳しくはこちら →https://ja.wikipedia.org/wiki/HSV%E8%89%B2%E7%A9%BA%E9%96%93

例）下限値=HSV(10,30,30), 上限値=HSV(20,225,225)
→HSV(10~20, 30~225, 30~225)

まず、HSV の上限値、下限値と画像データ(image)の 3 つを引数として、画像から上限値から下限値までの間の色のみを抽出する画像を出力する関数を作ります。以下は一例です。

```
def hsvExtraction(image, hsvLower, hsvUpper):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)  # 画像をHSVに変換
    hsv_mask = cv2.inRange(hsv, hsvLower, hsvUpper)  # HSVからマスクを作成
    result = cv2.bitwise_and(image, image, mask=hsv_mask)  # 元画像とマスクを合成
    return result
```

この関数の hsvLower, hsvUpper を適切に入力すればそれだけで色抽出は完了です。

しかし、実は赤は色相のちょうど 0 と 179 の間をまたいでいます。HSV の下限値と上限値の各値の上限が逆になっているとエラーを起こすため、面倒ですが H=0~5 と H=170~179 までの間で抽出した画像を合成するという方法で、抽出する関数例も紹介します。(既出の関数も使います。)

```
def red_masks_get(image):

    # HSVでの色抽出
    hsvLower_0 = np.array([0, 80, 100])    # 抽出する色の下限0(赤の抽出のため二つにわけて合成が必要)
    hsvLower_1 = np.array([170, 80, 100])  # 抽出する色の下限1(赤の抽出のため二つにわけて合成が必要)
    hsvUpper_0 = np.array([10, 255, 255])    # 抽出する色の上限0(赤の抽出のため二つにわけて合成が必要)
    hsvUpper_1 = np.array([179, 255, 255])   # 抽出する色の上限1(赤の抽出のため二つにわけて合成が必要)

    hsvResult_0 = hsvExtraction(image, hsvLower_0, hsvUpper_0)  # 画像0を作成
    hsvResult_1 = hsvExtraction(image, hsvLower_1, hsvUpper_1)  # 画像1を作成

    hsvResult = hsvResult_0 | hsvResult_1  # 画像を統合

    return hsvResult
```

### 3. 抽出した画像を 2 値化する

次に、抽出した画像を 2 値化します。これは、赤い部分の重心座標を出すことと、赤い部分が画像内で示す面積の計算のために行う手順です。2 値化する前に、準備段階として一度グレースケール化をします。(直接 2 値化もできると思います。)

グレースケール化は、画像の 1 ピクセル当たりの情報を明るさのみにします。これによって、赤色だけが抽出されたデータが白黒のデータに変換されます。

```
# グレースケール画像データを取得する関数
def gray_get(image):
    img = red_masks_get(image)
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # グレースケールで画像を読み込み
    return img_gray
```

OpenCV はとても有能なのでこれくらい簡単にかけてしまいます。続いて 2 値化をしていきます。

```
# 二値画像データを取得する関数
def binary_get(image):
    ret, img_binary = cv2.threshold(
    gray_get(image), 10, 255, cv2.THRESH_BINARY) # 2 値画像に変換
    return img_binary

```

ここではグレースケール化で得られた画像を使い、明るさ(0~225)の値の 10~225 の間に入るピクセルのみを 1 に、それ以外を 0 というデータとしました。これで、コーンのみが白く写り周りが真っ黒な、最大限まで簡素化されたデータが出力されました。

### 4. 2 値化する画像の中心座標を求める

最終段階です。2 値化した画像を使い、コーンの重心座標を求めます。

画像は 2 値化されているので、白い部分の重心座標を求めれば完了です。重心座標は、その座標から白いピクセルまでのベクトルをすべて足し合わせた結果 0 になる点です。以下の関数で表すことができます。

```
def center_get(image):
    mu = cv2.moments(binary_get(image), False)  # 重心関数作成

    if mu["m00"] != 0:
        x, y = int(mu["m10"]/mu["m00"]), int(mu["m01"]/mu["m00"])  # 重心座標の作成
        return [x, y]  # 重心座標を返り値に設定

    else:
        return [-20000, -20000]  # ありえない数字を返す
```

moments という関数が用意されているので、これも楽勝ですね。ただ注意すべき点は、画像に赤が全く見つからなかった時です。このときは、x,y の値の仮定で/0 が出てきてしまうので、エラーがでます。今回は適当にありえない値を返すことにしました。try 分を使ってもっと美しいコードを書くこともできるので挑戦してみてください。

## 実践

原理がわかったところで実践してみましょう。
"teach_03_Software/image-process/"の中身を見てください。

中には、images というフォルダーや、mdlreddetect.py, test.py などがあると思います。mdlreddetect.py は今までに説明した関数+α が収納されており、test.py は画像の色抽出を出力するファイルになっています。images には"image_origin.jpg"が格納されており、test.py を実行すると、これまで説明してきた画像変換の出力と、中心座標などの値をプリントしてくれます。

試しに、test.py を実行してみてください。images の画像がいくつか増え、コマンドラインにも出力結果の数値が表示されると思います。コマンドラインには、画像のサイズ、占有率、中心座標がプリントされます。出力された画像を確認し、これまでの手順をおさらいしましょう。

占有率の計算は手順では省きましたが、mdlreddetect.py を見ればすぐに理解できると思います。"image_origin.jpg"の画像を好きに変更していろいろと試してみましょう。

## 追記

画像処理の触りはこれで終了です。しかし、これを制御と結び付けるにはまだまださまざまな手順が必要です。

1. HSV の上限値と下限値を実験をして決める
2. 占有率と距離の関係を実験によって求める
3. 中心座標の位置に準じた CanSat の制御コードを作る
4. ゴール判定を実装する
5. コーンを見失った判定とそのときどのようにして探すのかを決め実装する
6. 画像処理走行の段階でゴールから離れすぎたとき、GPS 走行のフェーズに戻る
7. 画像のログを保存する
8. etc...

画像処理走行が 0m ゴールのカギになることは間違いないと思います。これまでの蓄積をうまく活用し、ぜひ優勝してください！
